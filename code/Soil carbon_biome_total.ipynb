{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d38307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce617a",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e7cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './'\n",
    "local_path_biome = '/bd_mir_bioma_without_xy.csv'\n",
    "file_path_biome = root_dir + local_path_biome\n",
    "\n",
    "df_biome = pd.read_csv(file_path_biome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b45e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_amazon = df_biome.where(df_biome['Bioma'] =='Amazon Rainforest').dropna(axis = 0)\n",
    "df_biome_atlantic= df_biome.where(df_biome['Bioma'] == 'Atlantic Forest').dropna(axis = 0)\n",
    "df_biome_caatinga = df_biome.where(df_biome['Bioma'] == 'Caatinga').dropna(axis = 0)\n",
    "df_biome_cerrado = df_biome.where(df_biome['Bioma'] == 'Cerrado').dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedfc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_amazon_data = df_biome_amazon.drop(['ID_Unico','Bioma','Carbon_gkg'], axis=1)\n",
    "df_biome_amazon_target = pd.DataFrame(df_biome_amazon, columns=['Carbon_gkg'])\n",
    "\n",
    "df_biome_atlantic_data = df_biome_atlantic.drop(['ID_Unico','Bioma','Carbon_gkg'], axis=1)\n",
    "df_biome_atlantic_target = pd.DataFrame(df_biome_atlantic, columns=['Carbon_gkg'])\n",
    "\n",
    "df_biome_caatinga_data = df_biome_caatinga.drop(['ID_Unico','Bioma','Carbon_gkg'], axis=1)\n",
    "df_biome_caatinga_target = pd.DataFrame(df_biome_caatinga, columns=['Carbon_gkg'])\n",
    "\n",
    "df_biome_cerrado_data = df_biome_cerrado.drop(['ID_Unico','Bioma','Carbon_gkg'], axis=1)\n",
    "df_biome_cerrado_target = pd.DataFrame(df_biome_cerrado, columns=['Carbon_gkg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b389d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex = df_biome_amazon_data['600'].idxmax()\n",
    "df_biome_amazon_data = df_biome_amazon_data.drop(index=index_ex)\n",
    "df_biome_amazon_target = df_biome_amazon_target.drop(index=index_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11dd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_amazon_data = df_biome_amazon_data.apply(lambda x:np.log(1/x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6b5a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "v = scipy.signal.savgol_filter(df_biome_amazon_data,21,3)\n",
    "for i in range(len(df_biome_amazon_data)):\n",
    "    for j in range(len(df_biome_amazon_data.iloc[i])):\n",
    "        df_biome_amazon_data.iloc[i][j] = v[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a075db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>3995</th>\n",
       "      <th>3990</th>\n",
       "      <th>3985</th>\n",
       "      <th>3980</th>\n",
       "      <th>3975</th>\n",
       "      <th>3970</th>\n",
       "      <th>3965</th>\n",
       "      <th>3960</th>\n",
       "      <th>3955</th>\n",
       "      <th>...</th>\n",
       "      <th>645</th>\n",
       "      <th>640</th>\n",
       "      <th>635</th>\n",
       "      <th>630</th>\n",
       "      <th>625</th>\n",
       "      <th>620</th>\n",
       "      <th>615</th>\n",
       "      <th>610</th>\n",
       "      <th>605</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227053</td>\n",
       "      <td>0.236588</td>\n",
       "      <td>0.243845</td>\n",
       "      <td>0.249272</td>\n",
       "      <td>0.253222</td>\n",
       "      <td>0.255991</td>\n",
       "      <td>0.257827</td>\n",
       "      <td>0.258955</td>\n",
       "      <td>0.259581</td>\n",
       "      <td>0.259898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495765</td>\n",
       "      <td>0.478052</td>\n",
       "      <td>0.455858</td>\n",
       "      <td>0.429113</td>\n",
       "      <td>0.397437</td>\n",
       "      <td>0.359978</td>\n",
       "      <td>0.315170</td>\n",
       "      <td>0.260487</td>\n",
       "      <td>0.192479</td>\n",
       "      <td>0.108138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.293778</td>\n",
       "      <td>0.294594</td>\n",
       "      <td>0.295111</td>\n",
       "      <td>0.295417</td>\n",
       "      <td>0.295575</td>\n",
       "      <td>0.295631</td>\n",
       "      <td>0.295620</td>\n",
       "      <td>0.295574</td>\n",
       "      <td>0.295519</td>\n",
       "      <td>0.295479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549961</td>\n",
       "      <td>0.520692</td>\n",
       "      <td>0.495270</td>\n",
       "      <td>0.474793</td>\n",
       "      <td>0.460569</td>\n",
       "      <td>0.454157</td>\n",
       "      <td>0.457340</td>\n",
       "      <td>0.471819</td>\n",
       "      <td>0.498143</td>\n",
       "      <td>0.533063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488040</td>\n",
       "      <td>0.485201</td>\n",
       "      <td>0.482634</td>\n",
       "      <td>0.480324</td>\n",
       "      <td>0.478241</td>\n",
       "      <td>0.476349</td>\n",
       "      <td>0.474610</td>\n",
       "      <td>0.472987</td>\n",
       "      <td>0.471443</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516493</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>0.482292</td>\n",
       "      <td>0.466953</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.445559</td>\n",
       "      <td>0.441951</td>\n",
       "      <td>0.444376</td>\n",
       "      <td>0.452526</td>\n",
       "      <td>0.463020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.508848</td>\n",
       "      <td>-1.524687</td>\n",
       "      <td>-1.535551</td>\n",
       "      <td>-1.542412</td>\n",
       "      <td>-1.546008</td>\n",
       "      <td>-1.546914</td>\n",
       "      <td>-1.545603</td>\n",
       "      <td>-1.542485</td>\n",
       "      <td>-1.537930</td>\n",
       "      <td>-1.532296</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.664564</td>\n",
       "      <td>-1.650781</td>\n",
       "      <td>-1.635020</td>\n",
       "      <td>-1.617387</td>\n",
       "      <td>-1.597609</td>\n",
       "      <td>-1.574532</td>\n",
       "      <td>-1.545144</td>\n",
       "      <td>-1.502730</td>\n",
       "      <td>-1.433873</td>\n",
       "      <td>-1.315793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.744479</td>\n",
       "      <td>0.739122</td>\n",
       "      <td>0.734120</td>\n",
       "      <td>0.729452</td>\n",
       "      <td>0.725077</td>\n",
       "      <td>0.720944</td>\n",
       "      <td>0.717002</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.709496</td>\n",
       "      <td>0.705846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751618</td>\n",
       "      <td>0.762536</td>\n",
       "      <td>0.779839</td>\n",
       "      <td>0.804364</td>\n",
       "      <td>0.837232</td>\n",
       "      <td>0.879737</td>\n",
       "      <td>0.932925</td>\n",
       "      <td>0.996392</td>\n",
       "      <td>1.065311</td>\n",
       "      <td>1.124858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.778622</td>\n",
       "      <td>0.774295</td>\n",
       "      <td>0.770712</td>\n",
       "      <td>0.767810</td>\n",
       "      <td>0.765510</td>\n",
       "      <td>0.763729</td>\n",
       "      <td>0.762384</td>\n",
       "      <td>0.761391</td>\n",
       "      <td>0.760667</td>\n",
       "      <td>0.760133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410685</td>\n",
       "      <td>0.402868</td>\n",
       "      <td>0.401583</td>\n",
       "      <td>0.409768</td>\n",
       "      <td>0.431023</td>\n",
       "      <td>0.469879</td>\n",
       "      <td>0.532002</td>\n",
       "      <td>0.623901</td>\n",
       "      <td>0.750843</td>\n",
       "      <td>0.910358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.394542</td>\n",
       "      <td>0.410374</td>\n",
       "      <td>0.422658</td>\n",
       "      <td>0.432061</td>\n",
       "      <td>0.439106</td>\n",
       "      <td>0.444214</td>\n",
       "      <td>0.447741</td>\n",
       "      <td>0.449996</td>\n",
       "      <td>0.451257</td>\n",
       "      <td>0.451787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694187</td>\n",
       "      <td>0.682291</td>\n",
       "      <td>0.680604</td>\n",
       "      <td>0.692435</td>\n",
       "      <td>0.721912</td>\n",
       "      <td>0.774250</td>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.973618</td>\n",
       "      <td>1.131839</td>\n",
       "      <td>1.323408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-0.822815</td>\n",
       "      <td>-0.858240</td>\n",
       "      <td>-0.886685</td>\n",
       "      <td>-0.909530</td>\n",
       "      <td>-0.927862</td>\n",
       "      <td>-0.942560</td>\n",
       "      <td>-0.954360</td>\n",
       "      <td>-0.963899</td>\n",
       "      <td>-0.971749</td>\n",
       "      <td>-0.978437</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.050054</td>\n",
       "      <td>-1.006573</td>\n",
       "      <td>-0.956588</td>\n",
       "      <td>-0.901257</td>\n",
       "      <td>-0.841411</td>\n",
       "      <td>-0.777386</td>\n",
       "      <td>-0.708746</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-0.549623</td>\n",
       "      <td>-0.451763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.541331</td>\n",
       "      <td>0.541756</td>\n",
       "      <td>0.541784</td>\n",
       "      <td>0.541524</td>\n",
       "      <td>0.541041</td>\n",
       "      <td>0.540378</td>\n",
       "      <td>0.539560</td>\n",
       "      <td>0.538606</td>\n",
       "      <td>0.537528</td>\n",
       "      <td>0.536338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659065</td>\n",
       "      <td>0.625416</td>\n",
       "      <td>0.597257</td>\n",
       "      <td>0.579414</td>\n",
       "      <td>0.577559</td>\n",
       "      <td>0.598650</td>\n",
       "      <td>0.651393</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.893227</td>\n",
       "      <td>1.094346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-0.139318</td>\n",
       "      <td>-0.131342</td>\n",
       "      <td>-0.125561</td>\n",
       "      <td>-0.121567</td>\n",
       "      <td>-0.119022</td>\n",
       "      <td>-0.117629</td>\n",
       "      <td>-0.117126</td>\n",
       "      <td>-0.117271</td>\n",
       "      <td>-0.117831</td>\n",
       "      <td>-0.118583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528020</td>\n",
       "      <td>0.524007</td>\n",
       "      <td>0.522142</td>\n",
       "      <td>0.523469</td>\n",
       "      <td>0.529189</td>\n",
       "      <td>0.540640</td>\n",
       "      <td>0.559128</td>\n",
       "      <td>0.585362</td>\n",
       "      <td>0.617939</td>\n",
       "      <td>0.650257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4000      3995      3990      3985      3980      3975      3970  \\\n",
       "0    0.227053  0.236588  0.243845  0.249272  0.253222  0.255991  0.257827   \n",
       "1    0.293778  0.294594  0.295111  0.295417  0.295575  0.295631  0.295620   \n",
       "2    0.488040  0.485201  0.482634  0.480324  0.478241  0.476349  0.474610   \n",
       "3   -1.508848 -1.524687 -1.535551 -1.542412 -1.546008 -1.546914 -1.545603   \n",
       "4    0.744479  0.739122  0.734120  0.729452  0.725077  0.720944  0.717002   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  0.778622  0.774295  0.770712  0.767810  0.765510  0.763729  0.762384   \n",
       "175  0.394542  0.410374  0.422658  0.432061  0.439106  0.444214  0.447741   \n",
       "176 -0.822815 -0.858240 -0.886685 -0.909530 -0.927862 -0.942560 -0.954360   \n",
       "177  0.541331  0.541756  0.541784  0.541524  0.541041  0.540378  0.539560   \n",
       "178 -0.139318 -0.131342 -0.125561 -0.121567 -0.119022 -0.117629 -0.117126   \n",
       "\n",
       "         3965      3960      3955  ...       645       640       635  \\\n",
       "0    0.258955  0.259581  0.259898  ...  0.495765  0.478052  0.455858   \n",
       "1    0.295574  0.295519  0.295479  ...  0.549961  0.520692  0.495270   \n",
       "2    0.472987  0.471443  0.469944  ...  0.516493  0.499163  0.482292   \n",
       "3   -1.542485 -1.537930 -1.532296  ... -1.664564 -1.650781 -1.635020   \n",
       "4    0.713202  0.709496  0.705846  ...  0.751618  0.762536  0.779839   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "174  0.761391  0.760667  0.760133  ...  0.410685  0.402868  0.401583   \n",
       "175  0.449996  0.451257  0.451787  ...  0.694187  0.682291  0.680604   \n",
       "176 -0.963899 -0.971749 -0.978437  ... -1.050054 -1.006573 -0.956588   \n",
       "177  0.538606  0.537528  0.536338  ...  0.659065  0.625416  0.597257   \n",
       "178 -0.117271 -0.117831 -0.118583  ...  0.528020  0.524007  0.522142   \n",
       "\n",
       "          630       625       620       615       610       605       600  \n",
       "0    0.429113  0.397437  0.359978  0.315170  0.260487  0.192479  0.108138  \n",
       "1    0.474793  0.460569  0.454157  0.457340  0.471819  0.498143  0.533063  \n",
       "2    0.466953  0.454300  0.445559  0.441951  0.444376  0.452526  0.463020  \n",
       "3   -1.617387 -1.597609 -1.574532 -1.545144 -1.502730 -1.433873 -1.315793  \n",
       "4    0.804364  0.837232  0.879737  0.932925  0.996392  1.065311  1.124858  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "174  0.409768  0.431023  0.469879  0.532002  0.623901  0.750843  0.910358  \n",
       "175  0.692435  0.721912  0.774250  0.855848  0.973618  1.131839  1.323408  \n",
       "176 -0.901257 -0.841411 -0.777386 -0.708746 -0.633881 -0.549623 -0.451763  \n",
       "177  0.579414  0.577559  0.598650  0.651393  0.746225  0.893227  1.094346  \n",
       "178  0.523469  0.529189  0.540640  0.559128  0.585362  0.617939  0.650257  \n",
       "\n",
       "[179 rows x 681 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "X = pipeline.fit_transform(df_biome_amazon_data)\n",
    "df_biome_amazon_data_tr = pd.DataFrame(X,columns=df_biome_amazon_data.columns)\n",
    "df_biome_amazon_data_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff5c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex = df_biome_atlantic_data['600'].idxmax()\n",
    "df_biome_atlantic_data = df_biome_atlantic_data.drop(index=index_ex)\n",
    "df_biome_atlantic_target = df_biome_atlantic_target.drop(index=index_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e41031",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex = df_biome_atlantic_data['600'].idxmax()\n",
    "df_biome_atlantic_data = df_biome_atlantic_data.drop(index=index_ex)\n",
    "df_biome_atlantic_target = df_biome_atlantic_target.drop(index=index_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d869c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_atlantic_data = df_biome_atlantic_data.apply(lambda x:np.log(1/x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4031312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scipy.signal.savgol_filter(df_biome_atlantic_data,21,3)\n",
    "for i in range(len(df_biome_atlantic_data)):\n",
    "    for j in range(len(df_biome_atlantic_data.iloc[i])):\n",
    "        df_biome_atlantic_data.iloc[i][j] = v[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb87311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>3995</th>\n",
       "      <th>3990</th>\n",
       "      <th>3985</th>\n",
       "      <th>3980</th>\n",
       "      <th>3975</th>\n",
       "      <th>3970</th>\n",
       "      <th>3965</th>\n",
       "      <th>3960</th>\n",
       "      <th>3955</th>\n",
       "      <th>...</th>\n",
       "      <th>645</th>\n",
       "      <th>640</th>\n",
       "      <th>635</th>\n",
       "      <th>630</th>\n",
       "      <th>625</th>\n",
       "      <th>620</th>\n",
       "      <th>615</th>\n",
       "      <th>610</th>\n",
       "      <th>605</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.089012</td>\n",
       "      <td>-0.095909</td>\n",
       "      <td>-0.100062</td>\n",
       "      <td>-0.101848</td>\n",
       "      <td>-0.101627</td>\n",
       "      <td>-0.099746</td>\n",
       "      <td>-0.096542</td>\n",
       "      <td>-0.092346</td>\n",
       "      <td>-0.087486</td>\n",
       "      <td>-0.082287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>0.787561</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.919193</td>\n",
       "      <td>0.995029</td>\n",
       "      <td>1.076403</td>\n",
       "      <td>1.161703</td>\n",
       "      <td>1.247622</td>\n",
       "      <td>1.327365</td>\n",
       "      <td>1.387989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779757</td>\n",
       "      <td>0.770365</td>\n",
       "      <td>0.763815</td>\n",
       "      <td>0.759913</td>\n",
       "      <td>0.758462</td>\n",
       "      <td>0.759265</td>\n",
       "      <td>0.762127</td>\n",
       "      <td>0.766854</td>\n",
       "      <td>0.773249</td>\n",
       "      <td>0.781117</td>\n",
       "      <td>...</td>\n",
       "      <td>2.221516</td>\n",
       "      <td>2.193142</td>\n",
       "      <td>2.182809</td>\n",
       "      <td>2.196466</td>\n",
       "      <td>2.241040</td>\n",
       "      <td>2.324589</td>\n",
       "      <td>2.456155</td>\n",
       "      <td>2.644718</td>\n",
       "      <td>2.896027</td>\n",
       "      <td>3.205281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.353282</td>\n",
       "      <td>-0.340123</td>\n",
       "      <td>-0.329402</td>\n",
       "      <td>-0.320853</td>\n",
       "      <td>-0.314216</td>\n",
       "      <td>-0.309238</td>\n",
       "      <td>-0.305674</td>\n",
       "      <td>-0.303284</td>\n",
       "      <td>-0.301833</td>\n",
       "      <td>-0.301088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148355</td>\n",
       "      <td>-0.160737</td>\n",
       "      <td>-0.161715</td>\n",
       "      <td>-0.149872</td>\n",
       "      <td>-0.123220</td>\n",
       "      <td>-0.079017</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>0.077712</td>\n",
       "      <td>0.199924</td>\n",
       "      <td>0.356480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.884734</td>\n",
       "      <td>-1.886147</td>\n",
       "      <td>-1.887007</td>\n",
       "      <td>-1.887462</td>\n",
       "      <td>-1.887614</td>\n",
       "      <td>-1.887536</td>\n",
       "      <td>-1.887276</td>\n",
       "      <td>-1.886874</td>\n",
       "      <td>-1.886359</td>\n",
       "      <td>-1.885760</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.089787</td>\n",
       "      <td>-2.081685</td>\n",
       "      <td>-2.071945</td>\n",
       "      <td>-2.059897</td>\n",
       "      <td>-2.044414</td>\n",
       "      <td>-2.023503</td>\n",
       "      <td>-1.993614</td>\n",
       "      <td>-1.948523</td>\n",
       "      <td>-1.877762</td>\n",
       "      <td>-1.765236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103073</td>\n",
       "      <td>0.104851</td>\n",
       "      <td>0.107623</td>\n",
       "      <td>0.111253</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.120553</td>\n",
       "      <td>0.125957</td>\n",
       "      <td>0.131686</td>\n",
       "      <td>0.137607</td>\n",
       "      <td>0.143583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212272</td>\n",
       "      <td>0.250390</td>\n",
       "      <td>0.290744</td>\n",
       "      <td>0.332833</td>\n",
       "      <td>0.376134</td>\n",
       "      <td>0.419971</td>\n",
       "      <td>0.463271</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.538890</td>\n",
       "      <td>0.561363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.056511</td>\n",
       "      <td>0.069571</td>\n",
       "      <td>0.080519</td>\n",
       "      <td>0.089603</td>\n",
       "      <td>0.097056</td>\n",
       "      <td>0.103098</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.111776</td>\n",
       "      <td>0.114810</td>\n",
       "      <td>0.117231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068311</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.053076</td>\n",
       "      <td>0.048524</td>\n",
       "      <td>0.047691</td>\n",
       "      <td>0.052138</td>\n",
       "      <td>0.063785</td>\n",
       "      <td>0.084973</td>\n",
       "      <td>0.118348</td>\n",
       "      <td>0.166210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.517860</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.567837</td>\n",
       "      <td>0.577898</td>\n",
       "      <td>0.585374</td>\n",
       "      <td>0.590657</td>\n",
       "      <td>0.594122</td>\n",
       "      <td>0.596137</td>\n",
       "      <td>0.597060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683283</td>\n",
       "      <td>0.728347</td>\n",
       "      <td>0.776144</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.870864</td>\n",
       "      <td>0.912182</td>\n",
       "      <td>0.944105</td>\n",
       "      <td>0.960220</td>\n",
       "      <td>0.950839</td>\n",
       "      <td>0.902051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.661629</td>\n",
       "      <td>-1.661171</td>\n",
       "      <td>-1.660501</td>\n",
       "      <td>-1.659762</td>\n",
       "      <td>-1.659060</td>\n",
       "      <td>-1.658475</td>\n",
       "      <td>-1.658066</td>\n",
       "      <td>-1.657885</td>\n",
       "      <td>-1.657976</td>\n",
       "      <td>-1.658383</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.549576</td>\n",
       "      <td>-1.525214</td>\n",
       "      <td>-1.499333</td>\n",
       "      <td>-1.472136</td>\n",
       "      <td>-1.443558</td>\n",
       "      <td>-1.413057</td>\n",
       "      <td>-1.379210</td>\n",
       "      <td>-1.339070</td>\n",
       "      <td>-1.287207</td>\n",
       "      <td>-1.214748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-0.491940</td>\n",
       "      <td>-0.487340</td>\n",
       "      <td>-0.483822</td>\n",
       "      <td>-0.481253</td>\n",
       "      <td>-0.479496</td>\n",
       "      <td>-0.478414</td>\n",
       "      <td>-0.477866</td>\n",
       "      <td>-0.477715</td>\n",
       "      <td>-0.477820</td>\n",
       "      <td>-0.478045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576491</td>\n",
       "      <td>-0.594165</td>\n",
       "      <td>-0.607074</td>\n",
       "      <td>-0.614302</td>\n",
       "      <td>-0.614574</td>\n",
       "      <td>-0.606048</td>\n",
       "      <td>-0.586001</td>\n",
       "      <td>-0.550430</td>\n",
       "      <td>-0.493687</td>\n",
       "      <td>-0.408725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.631729</td>\n",
       "      <td>-0.624023</td>\n",
       "      <td>-0.618181</td>\n",
       "      <td>-0.613973</td>\n",
       "      <td>-0.611166</td>\n",
       "      <td>-0.609525</td>\n",
       "      <td>-0.608819</td>\n",
       "      <td>-0.608816</td>\n",
       "      <td>-0.609285</td>\n",
       "      <td>-0.609998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329960</td>\n",
       "      <td>-0.333837</td>\n",
       "      <td>-0.335088</td>\n",
       "      <td>-0.332455</td>\n",
       "      <td>-0.324388</td>\n",
       "      <td>-0.308880</td>\n",
       "      <td>-0.283248</td>\n",
       "      <td>-0.243896</td>\n",
       "      <td>-0.186242</td>\n",
       "      <td>-0.105309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4000      3995      3990      3985      3980      3975      3970  \\\n",
       "0   -0.089012 -0.095909 -0.100062 -0.101848 -0.101627 -0.099746 -0.096542   \n",
       "1    0.779757  0.770365  0.763815  0.759913  0.758462  0.759265  0.762127   \n",
       "2   -0.353282 -0.340123 -0.329402 -0.320853 -0.314216 -0.309238 -0.305674   \n",
       "3   -1.884734 -1.886147 -1.887007 -1.887462 -1.887614 -1.887536 -1.887276   \n",
       "4    0.103073  0.104851  0.107623  0.111253  0.115607  0.120553  0.125957   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "173  0.056511  0.069571  0.080519  0.089603  0.097056  0.103098  0.107937   \n",
       "174  0.517860  0.538278  0.554777  0.567837  0.577898  0.585374  0.590657   \n",
       "175 -1.661629 -1.661171 -1.660501 -1.659762 -1.659060 -1.658475 -1.658066   \n",
       "176 -0.491940 -0.487340 -0.483822 -0.481253 -0.479496 -0.478414 -0.477866   \n",
       "177 -0.631729 -0.624023 -0.618181 -0.613973 -0.611166 -0.609525 -0.608819   \n",
       "\n",
       "         3965      3960      3955  ...       645       640       635  \\\n",
       "0   -0.092346 -0.087486 -0.082287  ...  0.733227  0.787561  0.849802   \n",
       "1    0.766854  0.773249  0.781117  ...  2.221516  2.193142  2.182809   \n",
       "2   -0.303284 -0.301833 -0.301088  ... -0.148355 -0.160737 -0.161715   \n",
       "3   -1.886874 -1.886359 -1.885760  ... -2.089787 -2.081685 -2.071945   \n",
       "4    0.131686  0.137607  0.143583  ...  0.212272  0.250390  0.290744   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "173  0.111776  0.114810  0.117231  ...  0.068311  0.060048  0.053076   \n",
       "174  0.594122  0.596137  0.597060  ...  0.683283  0.728347  0.776144   \n",
       "175 -1.657885 -1.657976 -1.658383  ... -1.549576 -1.525214 -1.499333   \n",
       "176 -0.477715 -0.477820 -0.478045  ... -0.576491 -0.594165 -0.607074   \n",
       "177 -0.608816 -0.609285 -0.609998  ... -0.329960 -0.333837 -0.335088   \n",
       "\n",
       "          630       625       620       615       610       605       600  \n",
       "0    0.919193  0.995029  1.076403  1.161703  1.247622  1.327365  1.387989  \n",
       "1    2.196466  2.241040  2.324589  2.456155  2.644718  2.896027  3.205281  \n",
       "2   -0.149872 -0.123220 -0.079017 -0.013585  0.077712  0.199924  0.356480  \n",
       "3   -2.059897 -2.044414 -2.023503 -1.993614 -1.948523 -1.877762 -1.765236  \n",
       "4    0.332833  0.376134  0.419971  0.463271  0.504100  0.538890  0.561363  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "173  0.048524  0.047691  0.052138  0.063785  0.084973  0.118348  0.166210  \n",
       "174  0.824478  0.870864  0.912182  0.944105  0.960220  0.950839  0.902051  \n",
       "175 -1.472136 -1.443558 -1.413057 -1.379210 -1.339070 -1.287207 -1.214748  \n",
       "176 -0.614302 -0.614574 -0.606048 -0.586001 -0.550430 -0.493687 -0.408725  \n",
       "177 -0.332455 -0.324388 -0.308880 -0.283248 -0.243896 -0.186242 -0.105309  \n",
       "\n",
       "[178 rows x 681 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pipeline.fit_transform(df_biome_atlantic_data)\n",
    "df_biome_atlantic_data_tr = pd.DataFrame(X,columns=df_biome_atlantic_data.columns)\n",
    "df_biome_atlantic_data_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bda30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex = df_biome_caatinga_data['3000'].idxmax()\n",
    "df_biome_caatinga_data = df_biome_caatinga_data.drop(index=index_ex)\n",
    "df_biome_caatinga_target = df_biome_caatinga_target.drop(index=index_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d18480",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex = df_biome_caatinga_data['3000'].idxmax()\n",
    "df_biome_caatinga_data = df_biome_caatinga_data.drop(index=index_ex)\n",
    "df_biome_caatinga_target = df_biome_caatinga_target.drop(index=index_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8566fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_caatinga_data = df_biome_caatinga_data.apply(lambda x:np.log(1/x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24582337",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scipy.signal.savgol_filter(df_biome_caatinga_data,21,3)\n",
    "for i in range(len(df_biome_caatinga_data)):\n",
    "    for j in range(len(df_biome_caatinga_data.iloc[i])):\n",
    "        df_biome_caatinga_data.iloc[i][j] = v[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335b1c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>3995</th>\n",
       "      <th>3990</th>\n",
       "      <th>3985</th>\n",
       "      <th>3980</th>\n",
       "      <th>3975</th>\n",
       "      <th>3970</th>\n",
       "      <th>3965</th>\n",
       "      <th>3960</th>\n",
       "      <th>3955</th>\n",
       "      <th>...</th>\n",
       "      <th>645</th>\n",
       "      <th>640</th>\n",
       "      <th>635</th>\n",
       "      <th>630</th>\n",
       "      <th>625</th>\n",
       "      <th>620</th>\n",
       "      <th>615</th>\n",
       "      <th>610</th>\n",
       "      <th>605</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.430411</td>\n",
       "      <td>-0.446952</td>\n",
       "      <td>-0.460128</td>\n",
       "      <td>-0.470422</td>\n",
       "      <td>-0.478253</td>\n",
       "      <td>-0.483995</td>\n",
       "      <td>-0.487979</td>\n",
       "      <td>-0.490513</td>\n",
       "      <td>-0.491883</td>\n",
       "      <td>-0.492364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.192948</td>\n",
       "      <td>0.181252</td>\n",
       "      <td>0.153408</td>\n",
       "      <td>0.103502</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>-0.095351</td>\n",
       "      <td>-0.261300</td>\n",
       "      <td>-0.469999</td>\n",
       "      <td>-0.692379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.451096</td>\n",
       "      <td>-1.476679</td>\n",
       "      <td>-1.497308</td>\n",
       "      <td>-1.513925</td>\n",
       "      <td>-1.527314</td>\n",
       "      <td>-1.538147</td>\n",
       "      <td>-1.547006</td>\n",
       "      <td>-1.554413</td>\n",
       "      <td>-1.560847</td>\n",
       "      <td>-1.566755</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.432424</td>\n",
       "      <td>-1.451912</td>\n",
       "      <td>-1.477270</td>\n",
       "      <td>-1.509077</td>\n",
       "      <td>-1.547111</td>\n",
       "      <td>-1.588717</td>\n",
       "      <td>-1.625402</td>\n",
       "      <td>-1.637340</td>\n",
       "      <td>-1.590358</td>\n",
       "      <td>-1.451041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.680311</td>\n",
       "      <td>-0.674480</td>\n",
       "      <td>-0.671033</td>\n",
       "      <td>-0.669706</td>\n",
       "      <td>-0.670205</td>\n",
       "      <td>-0.672221</td>\n",
       "      <td>-0.675435</td>\n",
       "      <td>-0.679518</td>\n",
       "      <td>-0.684139</td>\n",
       "      <td>-0.688960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087858</td>\n",
       "      <td>0.093159</td>\n",
       "      <td>0.089183</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>0.048526</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>-0.050860</td>\n",
       "      <td>-0.128610</td>\n",
       "      <td>-0.221656</td>\n",
       "      <td>-0.315207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.330805</td>\n",
       "      <td>0.332529</td>\n",
       "      <td>0.334454</td>\n",
       "      <td>0.336663</td>\n",
       "      <td>0.339219</td>\n",
       "      <td>0.342163</td>\n",
       "      <td>0.345526</td>\n",
       "      <td>0.349329</td>\n",
       "      <td>0.353587</td>\n",
       "      <td>0.358306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596733</td>\n",
       "      <td>-0.581971</td>\n",
       "      <td>-0.559754</td>\n",
       "      <td>-0.528264</td>\n",
       "      <td>-0.484631</td>\n",
       "      <td>-0.424396</td>\n",
       "      <td>-0.341153</td>\n",
       "      <td>-0.227681</td>\n",
       "      <td>-0.081461</td>\n",
       "      <td>0.084805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.500663</td>\n",
       "      <td>-0.483023</td>\n",
       "      <td>-0.468645</td>\n",
       "      <td>-0.457137</td>\n",
       "      <td>-0.448103</td>\n",
       "      <td>-0.441149</td>\n",
       "      <td>-0.435887</td>\n",
       "      <td>-0.431934</td>\n",
       "      <td>-0.428917</td>\n",
       "      <td>-0.426463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560890</td>\n",
       "      <td>-0.563423</td>\n",
       "      <td>-0.554261</td>\n",
       "      <td>-0.531119</td>\n",
       "      <td>-0.490366</td>\n",
       "      <td>-0.426371</td>\n",
       "      <td>-0.331146</td>\n",
       "      <td>-0.195909</td>\n",
       "      <td>-0.018203</td>\n",
       "      <td>0.185067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.964109</td>\n",
       "      <td>0.949838</td>\n",
       "      <td>0.938023</td>\n",
       "      <td>0.928369</td>\n",
       "      <td>0.920554</td>\n",
       "      <td>0.914244</td>\n",
       "      <td>0.909097</td>\n",
       "      <td>0.904770</td>\n",
       "      <td>0.900922</td>\n",
       "      <td>...</td>\n",
       "      <td>1.292375</td>\n",
       "      <td>1.293757</td>\n",
       "      <td>1.284360</td>\n",
       "      <td>1.258454</td>\n",
       "      <td>1.207846</td>\n",
       "      <td>1.120155</td>\n",
       "      <td>0.977021</td>\n",
       "      <td>0.755030</td>\n",
       "      <td>0.437210</td>\n",
       "      <td>0.040907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2.417724</td>\n",
       "      <td>2.391007</td>\n",
       "      <td>2.367344</td>\n",
       "      <td>2.346557</td>\n",
       "      <td>2.328323</td>\n",
       "      <td>2.312231</td>\n",
       "      <td>2.297810</td>\n",
       "      <td>2.284560</td>\n",
       "      <td>2.271963</td>\n",
       "      <td>2.259498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643869</td>\n",
       "      <td>0.662829</td>\n",
       "      <td>0.667350</td>\n",
       "      <td>0.650793</td>\n",
       "      <td>0.604168</td>\n",
       "      <td>0.514870</td>\n",
       "      <td>0.365954</td>\n",
       "      <td>0.139047</td>\n",
       "      <td>-0.172333</td>\n",
       "      <td>-0.538348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.773934</td>\n",
       "      <td>0.794832</td>\n",
       "      <td>0.810841</td>\n",
       "      <td>0.822754</td>\n",
       "      <td>0.831265</td>\n",
       "      <td>0.836985</td>\n",
       "      <td>0.840469</td>\n",
       "      <td>0.842228</td>\n",
       "      <td>0.842745</td>\n",
       "      <td>0.842484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511972</td>\n",
       "      <td>0.503921</td>\n",
       "      <td>0.491248</td>\n",
       "      <td>0.472118</td>\n",
       "      <td>0.443804</td>\n",
       "      <td>0.402139</td>\n",
       "      <td>0.340997</td>\n",
       "      <td>0.252872</td>\n",
       "      <td>0.133228</td>\n",
       "      <td>-0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.523192</td>\n",
       "      <td>-1.526113</td>\n",
       "      <td>-1.526985</td>\n",
       "      <td>-1.526286</td>\n",
       "      <td>-1.524365</td>\n",
       "      <td>-1.521478</td>\n",
       "      <td>-1.517821</td>\n",
       "      <td>-1.513546</td>\n",
       "      <td>-1.508779</td>\n",
       "      <td>-1.503631</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.316674</td>\n",
       "      <td>-1.333171</td>\n",
       "      <td>-1.345365</td>\n",
       "      <td>-1.351784</td>\n",
       "      <td>-1.349454</td>\n",
       "      <td>-1.332342</td>\n",
       "      <td>-1.288852</td>\n",
       "      <td>-1.199378</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>-0.799824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2.488292</td>\n",
       "      <td>2.491388</td>\n",
       "      <td>2.492543</td>\n",
       "      <td>2.492402</td>\n",
       "      <td>2.491414</td>\n",
       "      <td>2.489886</td>\n",
       "      <td>2.488028</td>\n",
       "      <td>2.485982</td>\n",
       "      <td>2.483854</td>\n",
       "      <td>2.481718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.124051</td>\n",
       "      <td>1.025316</td>\n",
       "      <td>0.921128</td>\n",
       "      <td>0.812530</td>\n",
       "      <td>0.699984</td>\n",
       "      <td>0.583301</td>\n",
       "      <td>0.461905</td>\n",
       "      <td>0.336193</td>\n",
       "      <td>0.211078</td>\n",
       "      <td>0.100170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4000      3995      3990      3985      3980      3975      3970  \\\n",
       "0   -0.430411 -0.446952 -0.460128 -0.470422 -0.478253 -0.483995 -0.487979   \n",
       "1   -1.451096 -1.476679 -1.497308 -1.513925 -1.527314 -1.538147 -1.547006   \n",
       "2   -0.680311 -0.674480 -0.671033 -0.669706 -0.670205 -0.672221 -0.675435   \n",
       "3    0.330805  0.332529  0.334454  0.336663  0.339219  0.342163  0.345526   \n",
       "4   -0.500663 -0.483023 -0.468645 -0.457137 -0.448103 -0.441149 -0.435887   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "173  0.981087  0.964109  0.949838  0.938023  0.928369  0.920554  0.914244   \n",
       "174  2.417724  2.391007  2.367344  2.346557  2.328323  2.312231  2.297810   \n",
       "175  0.773934  0.794832  0.810841  0.822754  0.831265  0.836985  0.840469   \n",
       "176 -1.523192 -1.526113 -1.526985 -1.526286 -1.524365 -1.521478 -1.517821   \n",
       "177  2.488292  2.491388  2.492543  2.492402  2.491414  2.489886  2.488028   \n",
       "\n",
       "         3965      3960      3955  ...       645       640       635  \\\n",
       "0   -0.490513 -0.491883 -0.492364  ...  0.192963  0.192948  0.181252   \n",
       "1   -1.554413 -1.560847 -1.566755  ... -1.432424 -1.451912 -1.477270   \n",
       "2   -0.679518 -0.684139 -0.688960  ...  0.087858  0.093159  0.089183   \n",
       "3    0.349329  0.353587  0.358306  ... -0.596733 -0.581971 -0.559754   \n",
       "4   -0.431934 -0.428917 -0.426463  ... -0.560890 -0.563423 -0.554261   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "173  0.909097  0.904770  0.900922  ...  1.292375  1.293757  1.284360   \n",
       "174  2.284560  2.271963  2.259498  ...  0.643869  0.662829  0.667350   \n",
       "175  0.842228  0.842745  0.842484  ...  0.511972  0.503921  0.491248   \n",
       "176 -1.513546 -1.508779 -1.503631  ... -1.316674 -1.333171 -1.345365   \n",
       "177  2.485982  2.483854  2.481718  ...  1.124051  1.025316  0.921128   \n",
       "\n",
       "          630       625       620       615       610       605       600  \n",
       "0    0.153408  0.103502  0.023715 -0.095351 -0.261300 -0.469999 -0.692379  \n",
       "1   -1.509077 -1.547111 -1.588717 -1.625402 -1.637340 -1.590358 -1.451041  \n",
       "2    0.074881  0.048526  0.007607 -0.050860 -0.128610 -0.221656 -0.315207  \n",
       "3   -0.528264 -0.484631 -0.424396 -0.341153 -0.227681 -0.081461  0.084805  \n",
       "4   -0.531119 -0.490366 -0.426371 -0.331146 -0.195909 -0.018203  0.185067  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "173  1.258454  1.207846  1.120155  0.977021  0.755030  0.437210  0.040907  \n",
       "174  0.650793  0.604168  0.514870  0.365954  0.139047 -0.172333 -0.538348  \n",
       "175  0.472118  0.443804  0.402139  0.340997  0.252872  0.133228 -0.009893  \n",
       "176 -1.351784 -1.349454 -1.332342 -1.288852 -1.199378 -1.039569 -0.799824  \n",
       "177  0.812530  0.699984  0.583301  0.461905  0.336193  0.211078  0.100170  \n",
       "\n",
       "[178 rows x 681 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pipeline.fit_transform(df_biome_caatinga_data)\n",
    "df_biome_caatinga_data_tr = pd.DataFrame(X,columns=df_biome_caatinga_data.columns)\n",
    "df_biome_caatinga_data_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e4cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex = df_biome_cerrado_data['600'].idxmax()\n",
    "df_biome_cerrado_data = df_biome_cerrado_data.drop(index=index_ex)\n",
    "df_biome_cerrado_target = df_biome_cerrado_target.drop(index=index_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f3203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_cerrado_data = df_biome_cerrado_data.apply(lambda x:np.log(1/x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28b5c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scipy.signal.savgol_filter(df_biome_cerrado_data,21,3)\n",
    "for i in range(len(df_biome_cerrado_data)):\n",
    "    for j in range(len(df_biome_cerrado_data.iloc[i])):\n",
    "        df_biome_cerrado_data.iloc[i][j] = v[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd7b3d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>3995</th>\n",
       "      <th>3990</th>\n",
       "      <th>3985</th>\n",
       "      <th>3980</th>\n",
       "      <th>3975</th>\n",
       "      <th>3970</th>\n",
       "      <th>3965</th>\n",
       "      <th>3960</th>\n",
       "      <th>3955</th>\n",
       "      <th>...</th>\n",
       "      <th>645</th>\n",
       "      <th>640</th>\n",
       "      <th>635</th>\n",
       "      <th>630</th>\n",
       "      <th>625</th>\n",
       "      <th>620</th>\n",
       "      <th>615</th>\n",
       "      <th>610</th>\n",
       "      <th>605</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.206533</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.220085</td>\n",
       "      <td>-0.224550</td>\n",
       "      <td>-0.227752</td>\n",
       "      <td>-0.229892</td>\n",
       "      <td>-0.231170</td>\n",
       "      <td>-0.231781</td>\n",
       "      <td>-0.231919</td>\n",
       "      <td>-0.231776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454009</td>\n",
       "      <td>-0.444880</td>\n",
       "      <td>-0.446599</td>\n",
       "      <td>-0.462615</td>\n",
       "      <td>-0.497303</td>\n",
       "      <td>-0.555948</td>\n",
       "      <td>-0.644110</td>\n",
       "      <td>-0.765428</td>\n",
       "      <td>-0.916593</td>\n",
       "      <td>-1.080559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.378909</td>\n",
       "      <td>0.363915</td>\n",
       "      <td>0.352528</td>\n",
       "      <td>0.344393</td>\n",
       "      <td>0.339119</td>\n",
       "      <td>0.336292</td>\n",
       "      <td>0.335485</td>\n",
       "      <td>0.336262</td>\n",
       "      <td>0.338179</td>\n",
       "      <td>0.340794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066823</td>\n",
       "      <td>0.062648</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.028660</td>\n",
       "      <td>-0.006687</td>\n",
       "      <td>-0.059312</td>\n",
       "      <td>-0.133837</td>\n",
       "      <td>-0.234251</td>\n",
       "      <td>-0.360496</td>\n",
       "      <td>-0.502902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.188330</td>\n",
       "      <td>-1.195369</td>\n",
       "      <td>-1.201344</td>\n",
       "      <td>-1.206490</td>\n",
       "      <td>-1.210987</td>\n",
       "      <td>-1.214970</td>\n",
       "      <td>-1.218545</td>\n",
       "      <td>-1.221795</td>\n",
       "      <td>-1.224789</td>\n",
       "      <td>-1.227590</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497149</td>\n",
       "      <td>-1.503979</td>\n",
       "      <td>-1.509985</td>\n",
       "      <td>-1.513756</td>\n",
       "      <td>-1.512889</td>\n",
       "      <td>-1.503088</td>\n",
       "      <td>-1.476723</td>\n",
       "      <td>-1.421105</td>\n",
       "      <td>-1.318381</td>\n",
       "      <td>-1.151998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.378665</td>\n",
       "      <td>0.389328</td>\n",
       "      <td>0.397647</td>\n",
       "      <td>0.403865</td>\n",
       "      <td>0.408218</td>\n",
       "      <td>0.410927</td>\n",
       "      <td>0.412212</td>\n",
       "      <td>0.412282</td>\n",
       "      <td>0.411347</td>\n",
       "      <td>0.409612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198265</td>\n",
       "      <td>0.253337</td>\n",
       "      <td>0.323514</td>\n",
       "      <td>0.411529</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.654606</td>\n",
       "      <td>0.815567</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.198872</td>\n",
       "      <td>1.378002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.811185</td>\n",
       "      <td>-0.800855</td>\n",
       "      <td>-0.791200</td>\n",
       "      <td>-0.782268</td>\n",
       "      <td>-0.774059</td>\n",
       "      <td>-0.766539</td>\n",
       "      <td>-0.759650</td>\n",
       "      <td>-0.753317</td>\n",
       "      <td>-0.747456</td>\n",
       "      <td>-0.741977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403431</td>\n",
       "      <td>0.453837</td>\n",
       "      <td>0.511775</td>\n",
       "      <td>0.575580</td>\n",
       "      <td>0.642942</td>\n",
       "      <td>0.710143</td>\n",
       "      <td>0.770702</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.820705</td>\n",
       "      <td>0.772130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.050991</td>\n",
       "      <td>-1.033208</td>\n",
       "      <td>-1.019187</td>\n",
       "      <td>-1.008570</td>\n",
       "      <td>-1.000932</td>\n",
       "      <td>-0.995795</td>\n",
       "      <td>-0.992652</td>\n",
       "      <td>-0.990971</td>\n",
       "      <td>-0.990209</td>\n",
       "      <td>-0.989818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184418</td>\n",
       "      <td>-0.124494</td>\n",
       "      <td>-0.042187</td>\n",
       "      <td>0.066234</td>\n",
       "      <td>0.205645</td>\n",
       "      <td>0.381805</td>\n",
       "      <td>0.599992</td>\n",
       "      <td>0.861023</td>\n",
       "      <td>1.152941</td>\n",
       "      <td>1.441032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.501211</td>\n",
       "      <td>0.490808</td>\n",
       "      <td>0.482141</td>\n",
       "      <td>0.475075</td>\n",
       "      <td>0.469443</td>\n",
       "      <td>0.465051</td>\n",
       "      <td>0.461690</td>\n",
       "      <td>0.459140</td>\n",
       "      <td>0.457177</td>\n",
       "      <td>0.455571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455813</td>\n",
       "      <td>0.408339</td>\n",
       "      <td>0.347676</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.173751</td>\n",
       "      <td>0.051624</td>\n",
       "      <td>-0.100848</td>\n",
       "      <td>-0.287005</td>\n",
       "      <td>-0.502778</td>\n",
       "      <td>-0.728748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.194059</td>\n",
       "      <td>0.187277</td>\n",
       "      <td>0.181898</td>\n",
       "      <td>0.177773</td>\n",
       "      <td>0.174740</td>\n",
       "      <td>0.172623</td>\n",
       "      <td>0.171241</td>\n",
       "      <td>0.170407</td>\n",
       "      <td>0.169934</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332245</td>\n",
       "      <td>-0.362543</td>\n",
       "      <td>-0.405682</td>\n",
       "      <td>-0.463794</td>\n",
       "      <td>-0.539511</td>\n",
       "      <td>-0.635620</td>\n",
       "      <td>-0.753938</td>\n",
       "      <td>-0.892539</td>\n",
       "      <td>-1.040709</td>\n",
       "      <td>-1.174294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.929361</td>\n",
       "      <td>-1.932635</td>\n",
       "      <td>-1.933855</td>\n",
       "      <td>-1.933491</td>\n",
       "      <td>-1.931924</td>\n",
       "      <td>-1.929458</td>\n",
       "      <td>-1.926349</td>\n",
       "      <td>-1.922816</td>\n",
       "      <td>-1.919057</td>\n",
       "      <td>-1.915256</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.043048</td>\n",
       "      <td>-0.986880</td>\n",
       "      <td>-0.915305</td>\n",
       "      <td>-0.826788</td>\n",
       "      <td>-0.718952</td>\n",
       "      <td>-0.588491</td>\n",
       "      <td>-0.431502</td>\n",
       "      <td>-0.245143</td>\n",
       "      <td>-0.032076</td>\n",
       "      <td>0.192251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.728164</td>\n",
       "      <td>0.723126</td>\n",
       "      <td>0.719463</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.715687</td>\n",
       "      <td>0.715193</td>\n",
       "      <td>0.715330</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>0.717077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092620</td>\n",
       "      <td>-0.082513</td>\n",
       "      <td>-0.074372</td>\n",
       "      <td>-0.068660</td>\n",
       "      <td>-0.066015</td>\n",
       "      <td>-0.067278</td>\n",
       "      <td>-0.073462</td>\n",
       "      <td>-0.085527</td>\n",
       "      <td>-0.103754</td>\n",
       "      <td>-0.126665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4000      3995      3990      3985      3980      3975      3970  \\\n",
       "0   -0.206533 -0.214149 -0.220085 -0.224550 -0.227752 -0.229892 -0.231170   \n",
       "1    0.378909  0.363915  0.352528  0.344393  0.339119  0.336292  0.335485   \n",
       "2   -1.188330 -1.195369 -1.201344 -1.206490 -1.210987 -1.214970 -1.218545   \n",
       "3    0.378665  0.389328  0.397647  0.403865  0.408218  0.410927  0.412212   \n",
       "4   -0.811185 -0.800855 -0.791200 -0.782268 -0.774059 -0.766539 -0.759650   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "173 -1.050991 -1.033208 -1.019187 -1.008570 -1.000932 -0.995795 -0.992652   \n",
       "174  0.501211  0.490808  0.482141  0.475075  0.469443  0.465051  0.461690   \n",
       "175  0.194059  0.187277  0.181898  0.177773  0.174740  0.172623  0.171241   \n",
       "176 -1.929361 -1.932635 -1.933855 -1.933491 -1.931924 -1.929458 -1.926349   \n",
       "177  0.728164  0.723126  0.719463  0.717042  0.715687  0.715193  0.715330   \n",
       "\n",
       "         3965      3960      3955  ...       645       640       635  \\\n",
       "0   -0.231781 -0.231919 -0.231776  ... -0.454009 -0.444880 -0.446599   \n",
       "1    0.336262  0.338179  0.340794  ...  0.066823  0.062648  0.050725   \n",
       "2   -1.221795 -1.224789 -1.227590  ... -1.497149 -1.503979 -1.509985   \n",
       "3    0.412282  0.411347  0.409612  ...  0.198265  0.253337  0.323514   \n",
       "4   -0.753317 -0.747456 -0.741977  ...  0.403431  0.453837  0.511775   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "173 -0.990971 -0.990209 -0.989818  ... -0.184418 -0.124494 -0.042187   \n",
       "174  0.459140  0.457177  0.455571  ...  0.455813  0.408339  0.347676   \n",
       "175  0.170407  0.169934  0.169631  ... -0.332245 -0.362543 -0.405682   \n",
       "176 -1.922816 -1.919057 -1.915256  ... -1.043048 -0.986880 -0.915305   \n",
       "177  0.715857  0.716524  0.717077  ... -0.092620 -0.082513 -0.074372   \n",
       "\n",
       "          630       625       620       615       610       605       600  \n",
       "0   -0.462615 -0.497303 -0.555948 -0.644110 -0.765428 -0.916593 -1.080559  \n",
       "1    0.028660 -0.006687 -0.059312 -0.133837 -0.234251 -0.360496 -0.502902  \n",
       "2   -1.513756 -1.512889 -1.503088 -1.476723 -1.421105 -1.318381 -1.151998  \n",
       "3    0.411529  0.520714  0.654606  0.815567  1.001370  1.198872  1.378002  \n",
       "4    0.575580  0.642942  0.710143  0.770702  0.813381  0.820705  0.772130  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "173  0.066234  0.205645  0.381805  0.599992  0.861023  1.152941  1.441032  \n",
       "174  0.270798  0.173751  0.051624 -0.100848 -0.287005 -0.502778 -0.728748  \n",
       "175 -0.463794 -0.539511 -0.635620 -0.753938 -0.892539 -1.040709 -1.174294  \n",
       "176 -0.826788 -0.718952 -0.588491 -0.431502 -0.245143 -0.032076  0.192251  \n",
       "177 -0.068660 -0.066015 -0.067278 -0.073462 -0.085527 -0.103754 -0.126665  \n",
       "\n",
       "[178 rows x 681 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pipeline.fit_transform(df_biome_cerrado_data)\n",
    "df_biome_cerrado_data_tr = pd.DataFrame(X,columns=df_biome_cerrado_data.columns)\n",
    "df_biome_cerrado_data_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc639b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_data_total = pd.concat([df_biome_amazon_data_tr,df_biome_atlantic_data_tr,df_biome_caatinga_data_tr,df_biome_cerrado_data_tr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a48a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_target = pd.concat([df_biome_amazon_target,df_biome_atlantic_target,df_biome_caatinga_target,df_biome_cerrado_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c070525",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56227e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_test = pd.read_csv('./bd_mir_biome_test_without_xy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffffaf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_test_data = df_biome_test.drop(['ID','ID_Unico','Bioma','Carbon_gkg'], axis=1)\n",
    "df_biome_test_target = pd.DataFrame(df_biome_test, columns=['Carbon_gkg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b302ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_test_data = df_biome_test_data.apply(lambda x:np.log(1/x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "212a43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.fit_transform(df_biome_test_data)\n",
    "df_biome_test_data_tr = pd.DataFrame(X,columns=df_biome_test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aafec0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_Unico</th>\n",
       "      <th>Bioma</th>\n",
       "      <th>Carbon_gkg</th>\n",
       "      <th>4000</th>\n",
       "      <th>3995</th>\n",
       "      <th>3990</th>\n",
       "      <th>3985</th>\n",
       "      <th>3980</th>\n",
       "      <th>3975</th>\n",
       "      <th>...</th>\n",
       "      <th>645</th>\n",
       "      <th>640</th>\n",
       "      <th>635</th>\n",
       "      <th>630</th>\n",
       "      <th>625</th>\n",
       "      <th>620</th>\n",
       "      <th>615</th>\n",
       "      <th>610</th>\n",
       "      <th>605</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>2979</td>\n",
       "      <td>Amazon Rainforest</td>\n",
       "      <td>7.976744</td>\n",
       "      <td>0.123735</td>\n",
       "      <td>0.123398</td>\n",
       "      <td>0.123916</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.123528</td>\n",
       "      <td>0.123434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021660</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>0.022476</td>\n",
       "      <td>0.021280</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.020970</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>0.019470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147</td>\n",
       "      <td>3076</td>\n",
       "      <td>Amazon Rainforest</td>\n",
       "      <td>9.883721</td>\n",
       "      <td>0.091380</td>\n",
       "      <td>0.090554</td>\n",
       "      <td>0.090354</td>\n",
       "      <td>0.090552</td>\n",
       "      <td>0.090528</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.003810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4785</td>\n",
       "      <td>47249</td>\n",
       "      <td>Amazon Rainforest</td>\n",
       "      <td>23.724826</td>\n",
       "      <td>0.076396</td>\n",
       "      <td>0.075970</td>\n",
       "      <td>0.075513</td>\n",
       "      <td>0.075046</td>\n",
       "      <td>0.074609</td>\n",
       "      <td>0.074049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.003209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1269</td>\n",
       "      <td>32623</td>\n",
       "      <td>Amazon Rainforest</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.105120</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.104752</td>\n",
       "      <td>0.104460</td>\n",
       "      <td>0.104386</td>\n",
       "      <td>0.103820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.009062</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.007087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>2974</td>\n",
       "      <td>Amazon Rainforest</td>\n",
       "      <td>5.319767</td>\n",
       "      <td>0.085765</td>\n",
       "      <td>0.085144</td>\n",
       "      <td>0.084572</td>\n",
       "      <td>0.084780</td>\n",
       "      <td>0.084394</td>\n",
       "      <td>0.083976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.011630</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>0.012870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3785</td>\n",
       "      <td>46249</td>\n",
       "      <td>Cerrado</td>\n",
       "      <td>19.141531</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>0.048110</td>\n",
       "      <td>0.048110</td>\n",
       "      <td>0.048133</td>\n",
       "      <td>0.048037</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.004767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3918</td>\n",
       "      <td>46382</td>\n",
       "      <td>Cerrado</td>\n",
       "      <td>8.120650</td>\n",
       "      <td>0.067633</td>\n",
       "      <td>0.067397</td>\n",
       "      <td>0.067237</td>\n",
       "      <td>0.067367</td>\n",
       "      <td>0.066970</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.005190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3957</td>\n",
       "      <td>46421</td>\n",
       "      <td>Cerrado</td>\n",
       "      <td>14.501160</td>\n",
       "      <td>0.059230</td>\n",
       "      <td>0.058790</td>\n",
       "      <td>0.058587</td>\n",
       "      <td>0.058550</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.058130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3969</td>\n",
       "      <td>46433</td>\n",
       "      <td>Cerrado</td>\n",
       "      <td>12.180974</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059327</td>\n",
       "      <td>0.059030</td>\n",
       "      <td>0.058993</td>\n",
       "      <td>0.058677</td>\n",
       "      <td>0.058487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.005287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3824</td>\n",
       "      <td>46288</td>\n",
       "      <td>Cerrado</td>\n",
       "      <td>13.921114</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.059187</td>\n",
       "      <td>0.058983</td>\n",
       "      <td>0.059077</td>\n",
       "      <td>0.058793</td>\n",
       "      <td>0.058453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.004570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 685 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  ID_Unico              Bioma  Carbon_gkg      4000      3995  \\\n",
       "0    136      2979  Amazon Rainforest    7.976744  0.123735  0.123398   \n",
       "1    147      3076  Amazon Rainforest    9.883721  0.091380  0.090554   \n",
       "2   4785     47249  Amazon Rainforest   23.724826  0.076396  0.075970   \n",
       "3   1269     32623  Amazon Rainforest    2.400000  0.105120  0.104962   \n",
       "4    134      2974  Amazon Rainforest    5.319767  0.085765  0.085144   \n",
       "..   ...       ...                ...         ...       ...       ...   \n",
       "95  3785     46249            Cerrado   19.141531  0.047971  0.048110   \n",
       "96  3918     46382            Cerrado    8.120650  0.067633  0.067397   \n",
       "97  3957     46421            Cerrado   14.501160  0.059230  0.058790   \n",
       "98  3969     46433            Cerrado   12.180974  0.059844  0.059327   \n",
       "99  3824     46288            Cerrado   13.921114  0.059592  0.059187   \n",
       "\n",
       "        3990      3985      3980      3975  ...       645       640       635  \\\n",
       "0   0.123916  0.123900  0.123528  0.123434  ...  0.021660  0.021178  0.021972   \n",
       "1   0.090354  0.090552  0.090528  0.089972  ...  0.005537  0.005698  0.005622   \n",
       "2   0.075513  0.075046  0.074609  0.074049  ...  0.002025  0.001944  0.002132   \n",
       "3   0.104752  0.104460  0.104386  0.103820  ...  0.009715  0.009378  0.008368   \n",
       "4   0.084572  0.084780  0.084394  0.083976  ...  0.007313  0.006954  0.007628   \n",
       "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "95  0.048110  0.048133  0.048037  0.047617  ...  0.003430  0.003433  0.002980   \n",
       "96  0.067237  0.067367  0.066970  0.066400  ...  0.003477  0.003157  0.003103   \n",
       "97  0.058587  0.058550  0.058700  0.058130  ...  0.004310  0.004197  0.004530   \n",
       "98  0.059030  0.058993  0.058677  0.058487  ...  0.003307  0.003820  0.003380   \n",
       "99  0.058983  0.059077  0.058793  0.058453  ...  0.003283  0.003880  0.004050   \n",
       "\n",
       "         630       625       620       615       610       605       600  \n",
       "0   0.022476  0.021280  0.019824  0.019386  0.020970  0.020618  0.019470  \n",
       "1   0.005698  0.005568  0.005318  0.005920  0.005142  0.003768  0.003810  \n",
       "2   0.002447  0.001485  0.001806  0.002634  0.002976  0.002911  0.003209  \n",
       "3   0.008416  0.009062  0.007692  0.008414  0.008834  0.007244  0.007087  \n",
       "4   0.007310  0.007704  0.007296  0.009508  0.011630  0.011970  0.012870  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.003877  0.003980  0.004157  0.004043  0.004687  0.004667  0.004767  \n",
       "96  0.003500  0.003720  0.003100  0.004530  0.004050  0.004587  0.005190  \n",
       "97  0.004173  0.005017  0.004983  0.005790  0.005513  0.005743  0.005397  \n",
       "98  0.004007  0.003833  0.005240  0.005313  0.004923  0.005910  0.005287  \n",
       "99  0.003750  0.003513  0.003910  0.004187  0.004577  0.004017  0.004570  \n",
       "\n",
       "[100 rows x 685 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_biome_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5422d3",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc349f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2ddea960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "forest_reg_setup = RandomForestRegressor()\n",
    "param_grid = {'n_estimators': [10,100,1000]}\n",
    "gsearch = GridSearchCV(forest_reg_setup, param_grid)\n",
    "forest_reg = gsearch.fit(df_biome_data_total, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8e39b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 6.546942823497352\n",
      "R2: 0.38672042908014737\n"
     ]
    }
   ],
   "source": [
    "Y_predict_forest = forest_reg.predict(df_biome_test_data_tr)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_forest)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8db86d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/forest_reg.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(forest_reg, './model/biome/forest_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7776be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA\n",
    "df_biome_test_data_tr_ = df_biome_test_data_tr\n",
    "ew_test, ev_test = np.linalg.eig(np.cov(df_biome_data_total.T))\n",
    "ew_test_order = np.argsort(ew_test)[::-1]\n",
    "ew_test_sort = ew_test[ew_test_order]\n",
    "ev_test_sort = ev_test[:,ew_test_order]\n",
    "pd.DataFrame(ew_test_sort[0:15]).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f26e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d03ab025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_test = PCA(n_components=10)\n",
    "pca_test.fit(df_biome_data_total)\n",
    "df_biome_data_total_pca = pca_test.transform(df_biome_data_total)\n",
    "\n",
    "ols_test = linear_model.LinearRegression()\n",
    "ols_test.fit(df_biome_data_total_pca, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f696b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/pca_test.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pca_test, './model/biome/pca_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e1974ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 6.356309013629144\n",
      "R2: 0.4219153912655349\n"
     ]
    }
   ],
   "source": [
    "df_biome_test_data_tr_pca = pca_test.transform(df_biome_test_data_tr)\n",
    "Y_predict_test_pca = ols_test.predict(df_biome_test_data_tr_pca)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_test_pca)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_test_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2e35fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/ols_test.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ols_test, './model/biome/ols_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d5e0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLSR\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa45099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_model_test_setup = PLSRegression(scale=True)\n",
    "param_grid = {'n_components': range(1,20)}\n",
    "gsearch = GridSearchCV(pls_model_test_setup, param_grid)\n",
    "pls_model_test = gsearch.fit(df_biome_data_total, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "618a4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 5.9038714689755905\n",
      "R2: 0.5012818315958206\n"
     ]
    }
   ],
   "source": [
    "Y_predict_test_pls = pls_model_test.predict(df_biome_test_data_tr)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_test_pls)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_test_pls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "987a4939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/pls_model_test.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pls_model_test, './model/biome/pls_model_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea6cbe",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b0d540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_select(df):\n",
    "    index_2268 = []\n",
    "    for i in range(2265,2391,5):\n",
    "        index_2268.append(str(i))\n",
    "    index_2268.sort(reverse=True)\n",
    "    indexs_bands = index_2268\n",
    "    indexs_bands.extend(['630','625','620','615','610','605','600'])\n",
    "    df_band = pd.DataFrame(df,columns=indexs_bands)\n",
    "    return df_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "edfcf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_data_total_628 = band_select(df_biome_data_total)\n",
    "df_biome_test_data_tr_628 = band_select(df_biome_test_data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f341a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "forest_reg_setup = RandomForestRegressor()\n",
    "param_grid = {'n_estimators': [10,40,100,500]}\n",
    "gsearch = GridSearchCV(forest_reg_setup, param_grid)\n",
    "forest_reg_628 = gsearch.fit(df_biome_data_total_628, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a6eb3e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 7.772534982948992\n",
      "R2: 0.13561589393224538\n"
     ]
    }
   ],
   "source": [
    "Y_predict_forest = forest_reg_628.predict(df_biome_test_data_tr_628)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_forest)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cabaab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/forest_reg_628.pkl']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(forest_reg_628, './model/biome/forest_reg_628.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d92ce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA\n",
    "ew_test, ev_test = np.linalg.eig(np.cov(df_biome_data_total_628.T))\n",
    "ew_test_order = np.argsort(ew_test)[::-1]\n",
    "ew_test_sort = ew_test[ew_test_order]\n",
    "ev_test_sort = ev_test[:,ew_test_order]\n",
    "pd.DataFrame(ew_test_sort[0:15]).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a74a8685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_628 = PCA(n_components=5)\n",
    "pca_628.fit(df_biome_data_total_628)\n",
    "df_biome_data_total_pca = pca_628.transform(df_biome_data_total_628)\n",
    "\n",
    "ols_628 = linear_model.LinearRegression()\n",
    "ols_628.fit(df_biome_data_total_pca, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "69524d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/pca_628.pkl']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pca_628, './model/biome/pca_628.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c20bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 6.762125826005516\n",
      "R2: 0.34574372437149803\n"
     ]
    }
   ],
   "source": [
    "df_biome_test_data_tr_628_pca = pca_628.transform(df_biome_test_data_tr_628)\n",
    "Y_predict_ols = ols_628.predict(df_biome_test_data_tr_628_pca)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_ols)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_ols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7656b243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/ols_628.pkl']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ols_628, './model/biome/ols_628.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a7421",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biome_data_total, df_biome_target\n",
    "df_biome_test_data_tr,df_biome_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "34c7d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Lasso to find important features\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4331d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13891.543462103746, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13993.652201278115, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14717.2633493955, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15922.963429346915, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16135.155839290552, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13517.039556694357, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14552.15910009926, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14635.713663745639, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16272.158974993179, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16224.009641325192, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13891.543436122738, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13993.652182587362, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14717.263331621989, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15922.963380546014, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16135.15580356652, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13517.039521185769, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14552.159038375992, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14635.713640587468, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16272.15894386771, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16224.009610204414, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13891.540863930166, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13993.650332159817, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14717.261572015226, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15922.958549169893, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16135.152266788915, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13517.036005785461, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14552.152927687688, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14635.71134789603, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16272.155862381333, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16224.0065291926, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13391.6213426201, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13608.85303490453, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14361.706580567621, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15173.999294747484, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15499.631404503865, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12974.56159538602, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13585.422873323261, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14203.037285025355, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15739.404816973942, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15666.054278255786, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1256.281434463992, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3552.667755696444, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3367.490025000803, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1346.7256360089414, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2673.855132243203, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 853.4404856093352, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1445.7474711018767, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 885.6136611437541, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3148.46430174982, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2351.8032369990615, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2071.30096264253, tolerance: 6.983299911983394\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "para = {'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,40,50,100,200,500]}\n",
    "lassore = GridSearchCV(lasso, para, cv=10)\n",
    "lassore.fit(df_biome_data_total, df_biome_target)\n",
    "print(lassore.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "40b05ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1256.281434463992, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3552.667755696444, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3367.490025000803, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1346.7256360089414, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2673.855132243203, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 853.4404856093352, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1445.7474711018767, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 885.6136611437541, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3148.46430174982, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2351.8032369990615, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162.6567792348069, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226.910853221656, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184.36353639079243, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 179.6860509840917, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 147.73233300453285, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 147.4209291848456, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185.47615035852505, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162.96271599597821, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 179.89121315662487, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 217.79668385731202, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.22268124815673, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106.97474316814987, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.66039325885504, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89.64014957304607, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81.52060722377064, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.31329405244105, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.71299163519507, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.24758742037011, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.81802406257339, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87.9723156612963, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.283916167722055, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.40003236845223, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.060226522851735, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115.43577628568164, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.19388509392593, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.289322459077084, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.30135886059725, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.93664688955323, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.24514577884838, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.634333779824374, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.69448976597414, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.786165281529975, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.21688210935099, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81.5159009488998, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.439121244351554, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.106360698173376, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.507026526342088, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.04283835943352, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.843548145829118, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.47438273867738, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.16043433730374, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.15641423971101, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.250007667695172, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.597841458875337, tolerance: 6.654219939843906\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.49446377503773, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.26286370719754, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.468490469793323, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.430260138724407, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.37113115372631, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.70161716738221, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.520788688765606, tolerance: 6.01236014302662\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.611908598693844, tolerance: 6.126706579132951\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.384513634780888, tolerance: 6.035149126350471\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.695991041793604, tolerance: 6.539039939326059\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.28952471599041, tolerance: 5.892994780106327\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.272418914908485, tolerance: 6.16503975451747\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.663340941478964, tolerance: 5.932544343792934\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.746693699416937, tolerance: 6.7112335484427605\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.248630486668844, tolerance: 6.6702517781239825\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.16460253554396, tolerance: 6.983299911983394\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "para = {'alpha':[0.01,0.02,0.03,0.04,0.05,0.09,0.1]}\n",
    "lassore = GridSearchCV(lasso, para, cv=10)\n",
    "lassore.fit(df_biome_data_total, df_biome_target)\n",
    "print(lassore.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa6635b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.16460253554396, tolerance: 6.983299911983394\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.03)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.03)\n",
    "lasso.fit(df_biome_data_total, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c2947b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rele = np.round(lasso.coef_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7ceb5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 4000                                     11.477230\n",
      " 2) 1590                                     3.720300\n",
      " 3) 675                                      2.900110\n",
      " 4) 705                                      2.556230\n",
      " 5) 2035                                     1.903540\n",
      " 6) 1005                                     1.875550\n",
      " 7) 1250                                     1.612840\n",
      " 8) 1425                                     1.542220\n",
      " 9) 3465                                     1.076880\n",
      "10) 865                                      1.019210\n",
      "11) 1050                                     0.991920\n",
      "12) 1440                                     0.970120\n",
      "13) 1300                                     0.869250\n",
      "14) 1415                                     0.808900\n",
      "15) 1255                                     0.725630\n",
      "16) 635                                      0.672180\n",
      "17) 2645                                     0.475480\n",
      "18) 1055                                     0.448000\n",
      "19) 1010                                     0.446470\n",
      "20) 2640                                     0.426130\n",
      "21) 2650                                     0.415500\n",
      "22) 2660                                     0.405740\n",
      "23) 2635                                     0.390150\n",
      "24) 2040                                     0.378600\n",
      "25) 3470                                     0.343230\n",
      "26) 2655                                     0.326610\n",
      "27) 870                                      0.315580\n",
      "28) 3370                                     0.267030\n",
      "29) 710                                      0.247820\n",
      "30) 1245                                     0.127840\n",
      "31) 3365                                     0.039560\n",
      "32) 2790                                     -0.000000\n",
      "33) 2890                                     0.000000\n",
      "34) 2895                                     0.000000\n",
      "35) 2905                                     0.000000\n"
     ]
    }
   ],
   "source": [
    "df_data_tr = pd.DataFrame(df_biome_amazon_data_tr,columns=df_biome_amazon_data_tr.columns)\n",
    "indices = np.argsort(rele)[::-1]\n",
    "cols = df_data_tr.columns[0:]\n",
    "for f in range(35):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 40, cols[indices[f]], rele[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0336872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_bands(df,num):\n",
    "    index_lasso = []\n",
    "    for f in range(num):\n",
    "        index_lasso.append(str(cols[indices[f]]))\n",
    "    df_bands_lasso = pd.DataFrame(df,columns=index_lasso)\n",
    "    return df_bands_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3904779f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>1590</th>\n",
       "      <th>675</th>\n",
       "      <th>705</th>\n",
       "      <th>2035</th>\n",
       "      <th>1005</th>\n",
       "      <th>1250</th>\n",
       "      <th>1425</th>\n",
       "      <th>3465</th>\n",
       "      <th>865</th>\n",
       "      <th>...</th>\n",
       "      <th>2660</th>\n",
       "      <th>2635</th>\n",
       "      <th>2040</th>\n",
       "      <th>3470</th>\n",
       "      <th>2655</th>\n",
       "      <th>870</th>\n",
       "      <th>3370</th>\n",
       "      <th>710</th>\n",
       "      <th>1245</th>\n",
       "      <th>3365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227053</td>\n",
       "      <td>-1.040726</td>\n",
       "      <td>0.454799</td>\n",
       "      <td>0.391177</td>\n",
       "      <td>-0.914149</td>\n",
       "      <td>0.385281</td>\n",
       "      <td>0.136822</td>\n",
       "      <td>-0.994782</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>0.274356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557432</td>\n",
       "      <td>-0.588117</td>\n",
       "      <td>-0.919904</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>-0.564008</td>\n",
       "      <td>0.354457</td>\n",
       "      <td>-0.054134</td>\n",
       "      <td>0.389815</td>\n",
       "      <td>0.132473</td>\n",
       "      <td>-0.056936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.293778</td>\n",
       "      <td>-1.467541</td>\n",
       "      <td>0.746259</td>\n",
       "      <td>0.657944</td>\n",
       "      <td>-0.811683</td>\n",
       "      <td>0.532935</td>\n",
       "      <td>0.552719</td>\n",
       "      <td>-1.067934</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>0.073227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207024</td>\n",
       "      <td>-0.217905</td>\n",
       "      <td>-0.784982</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>-0.209091</td>\n",
       "      <td>0.168592</td>\n",
       "      <td>0.017306</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0.564505</td>\n",
       "      <td>0.017589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488040</td>\n",
       "      <td>1.733324</td>\n",
       "      <td>0.533757</td>\n",
       "      <td>0.528511</td>\n",
       "      <td>-0.385649</td>\n",
       "      <td>0.626464</td>\n",
       "      <td>0.243722</td>\n",
       "      <td>0.056314</td>\n",
       "      <td>1.082065</td>\n",
       "      <td>0.682897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349521</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>-0.315638</td>\n",
       "      <td>1.083586</td>\n",
       "      <td>0.343432</td>\n",
       "      <td>0.703517</td>\n",
       "      <td>1.143352</td>\n",
       "      <td>0.508494</td>\n",
       "      <td>0.255275</td>\n",
       "      <td>1.143934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.508848</td>\n",
       "      <td>0.286296</td>\n",
       "      <td>-1.678560</td>\n",
       "      <td>-1.634205</td>\n",
       "      <td>0.876432</td>\n",
       "      <td>-1.505733</td>\n",
       "      <td>-1.787928</td>\n",
       "      <td>1.132200</td>\n",
       "      <td>-1.612316</td>\n",
       "      <td>-1.207880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.911675</td>\n",
       "      <td>-0.900137</td>\n",
       "      <td>0.694698</td>\n",
       "      <td>-1.608312</td>\n",
       "      <td>-0.908137</td>\n",
       "      <td>-1.316383</td>\n",
       "      <td>-1.514151</td>\n",
       "      <td>-1.617782</td>\n",
       "      <td>-1.785759</td>\n",
       "      <td>-1.510567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.744479</td>\n",
       "      <td>-0.521106</td>\n",
       "      <td>0.830539</td>\n",
       "      <td>0.698912</td>\n",
       "      <td>-0.532279</td>\n",
       "      <td>0.847582</td>\n",
       "      <td>0.669042</td>\n",
       "      <td>-0.663877</td>\n",
       "      <td>0.376659</td>\n",
       "      <td>0.312843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531534</td>\n",
       "      <td>0.547729</td>\n",
       "      <td>-0.480257</td>\n",
       "      <td>0.382440</td>\n",
       "      <td>0.535141</td>\n",
       "      <td>0.396141</td>\n",
       "      <td>0.346252</td>\n",
       "      <td>0.677329</td>\n",
       "      <td>0.678222</td>\n",
       "      <td>0.342986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.050991</td>\n",
       "      <td>0.396339</td>\n",
       "      <td>-0.066864</td>\n",
       "      <td>-0.209644</td>\n",
       "      <td>-0.435256</td>\n",
       "      <td>0.331938</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.422365</td>\n",
       "      <td>-1.105156</td>\n",
       "      <td>-0.417325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.406150</td>\n",
       "      <td>-0.428742</td>\n",
       "      <td>-0.544800</td>\n",
       "      <td>-1.094638</td>\n",
       "      <td>-0.410782</td>\n",
       "      <td>-0.377136</td>\n",
       "      <td>-0.916944</td>\n",
       "      <td>-0.244402</td>\n",
       "      <td>-0.053761</td>\n",
       "      <td>-0.894487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.501211</td>\n",
       "      <td>-0.991157</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.662554</td>\n",
       "      <td>-0.730210</td>\n",
       "      <td>0.233073</td>\n",
       "      <td>0.886686</td>\n",
       "      <td>-1.137430</td>\n",
       "      <td>0.311203</td>\n",
       "      <td>0.356262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393126</td>\n",
       "      <td>0.398894</td>\n",
       "      <td>-0.600144</td>\n",
       "      <td>0.304641</td>\n",
       "      <td>0.394420</td>\n",
       "      <td>0.350018</td>\n",
       "      <td>0.308058</td>\n",
       "      <td>0.682292</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.309258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.194059</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.436480</td>\n",
       "      <td>-0.541615</td>\n",
       "      <td>-0.747605</td>\n",
       "      <td>-0.630420</td>\n",
       "      <td>-0.241041</td>\n",
       "      <td>-0.268530</td>\n",
       "      <td>-0.736845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274992</td>\n",
       "      <td>-0.273232</td>\n",
       "      <td>-0.520566</td>\n",
       "      <td>-0.255922</td>\n",
       "      <td>-0.274725</td>\n",
       "      <td>-0.738420</td>\n",
       "      <td>-0.265642</td>\n",
       "      <td>-0.423904</td>\n",
       "      <td>-0.641110</td>\n",
       "      <td>-0.257512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.929361</td>\n",
       "      <td>-0.381492</td>\n",
       "      <td>-0.905747</td>\n",
       "      <td>-1.098156</td>\n",
       "      <td>-1.435605</td>\n",
       "      <td>-0.417674</td>\n",
       "      <td>0.047592</td>\n",
       "      <td>0.196631</td>\n",
       "      <td>-1.879276</td>\n",
       "      <td>-1.729018</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.757016</td>\n",
       "      <td>-1.745735</td>\n",
       "      <td>-1.595476</td>\n",
       "      <td>-1.890775</td>\n",
       "      <td>-1.754954</td>\n",
       "      <td>-1.694500</td>\n",
       "      <td>-1.887920</td>\n",
       "      <td>-1.165284</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-1.888398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.728164</td>\n",
       "      <td>0.570813</td>\n",
       "      <td>-0.199248</td>\n",
       "      <td>-0.177584</td>\n",
       "      <td>0.744264</td>\n",
       "      <td>-0.269110</td>\n",
       "      <td>-0.588829</td>\n",
       "      <td>0.569725</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>-0.126170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251575</td>\n",
       "      <td>0.251362</td>\n",
       "      <td>0.754429</td>\n",
       "      <td>0.123976</td>\n",
       "      <td>0.250695</td>\n",
       "      <td>-0.120633</td>\n",
       "      <td>0.145172</td>\n",
       "      <td>-0.157209</td>\n",
       "      <td>-0.614617</td>\n",
       "      <td>0.153447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4000      1590       675       705      2035      1005      1250  \\\n",
       "0    0.227053 -1.040726  0.454799  0.391177 -0.914149  0.385281  0.136822   \n",
       "1    0.293778 -1.467541  0.746259  0.657944 -0.811683  0.532935  0.552719   \n",
       "2    0.488040  1.733324  0.533757  0.528511 -0.385649  0.626464  0.243722   \n",
       "3   -1.508848  0.286296 -1.678560 -1.634205  0.876432 -1.505733 -1.787928   \n",
       "4    0.744479 -0.521106  0.830539  0.698912 -0.532279  0.847582  0.669042   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "173 -1.050991  0.396339 -0.066864 -0.209644 -0.435256  0.331938  0.001184   \n",
       "174  0.501211 -0.991157  0.505998  0.662554 -0.730210  0.233073  0.886686   \n",
       "175  0.194059 -0.341235 -0.405425 -0.436480 -0.541615 -0.747605 -0.630420   \n",
       "176 -1.929361 -0.381492 -0.905747 -1.098156 -1.435605 -0.417674  0.047592   \n",
       "177  0.728164  0.570813 -0.199248 -0.177584  0.744264 -0.269110 -0.588829   \n",
       "\n",
       "         1425      3465       865  ...      2660      2635      2040  \\\n",
       "0   -0.994782  0.012625  0.274356  ... -0.557432 -0.588117 -0.919904   \n",
       "1   -1.067934  0.026573  0.073227  ... -0.207024 -0.217905 -0.784982   \n",
       "2    0.056314  1.082065  0.682897  ...  0.349521  0.321600 -0.315638   \n",
       "3    1.132200 -1.612316 -1.207880  ... -0.911675 -0.900137  0.694698   \n",
       "4   -0.663877  0.376659  0.312843  ...  0.531534  0.547729 -0.480257   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "173  0.422365 -1.105156 -0.417325  ... -0.406150 -0.428742 -0.544800   \n",
       "174 -1.137430  0.311203  0.356262  ...  0.393126  0.398894 -0.600144   \n",
       "175 -0.241041 -0.268530 -0.736845  ... -0.274992 -0.273232 -0.520566   \n",
       "176  0.196631 -1.879276 -1.729018  ... -1.757016 -1.745735 -1.595476   \n",
       "177  0.569725  0.108541 -0.126170  ...  0.251575  0.251362  0.754429   \n",
       "\n",
       "         3470      2655       870      3370       710      1245      3365  \n",
       "0    0.019804 -0.564008  0.354457 -0.054134  0.389815  0.132473 -0.056936  \n",
       "1    0.030508 -0.209091  0.168592  0.017306  0.648952  0.564505  0.017589  \n",
       "2    1.083586  0.343432  0.703517  1.143352  0.508494  0.255275  1.143934  \n",
       "3   -1.608312 -0.908137 -1.316383 -1.514151 -1.617782 -1.785759 -1.510567  \n",
       "4    0.382440  0.535141  0.396141  0.346252  0.677329  0.678222  0.342986  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "173 -1.094638 -0.410782 -0.377136 -0.916944 -0.244402 -0.053761 -0.894487  \n",
       "174  0.304641  0.394420  0.350018  0.308058  0.682292  0.937255  0.309258  \n",
       "175 -0.255922 -0.274725 -0.738420 -0.265642 -0.423904 -0.641110 -0.257512  \n",
       "176 -1.890775 -1.754954 -1.694500 -1.887920 -1.165284  0.007812 -1.888398  \n",
       "177  0.123976  0.250695 -0.120633  0.145172 -0.157209 -0.614617  0.153447  \n",
       "\n",
       "[713 rows x 31 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_biome_data_total_lasso = lasso_bands(df_biome_data_total,31)\n",
    "df_biome_test_data_tr_lasso = lasso_bands(df_biome_test_data_tr,31)\n",
    "df_biome_data_total_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1e6a755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "D:\\softwareForLearn\\anaconda\\inss\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "rf_total_lasso_setup = RandomForestRegressor()\n",
    "param_grid = {'n_estimators': [10,30,100,1000]}\n",
    "gsearch = GridSearchCV(rf_total_lasso_setup, param_grid)\n",
    "rf_total_lasso = gsearch.fit(df_biome_data_total_lasso, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9c3c6cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 6.26060570717342\n",
      "R2: 0.43919211990425444\n"
     ]
    }
   ],
   "source": [
    "Y_predict_for_lasso = rf_total_lasso.predict(df_biome_test_data_tr_lasso)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_for_lasso)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_for_lasso)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "82caefe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/rf_total_lasso.pkl']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_total_lasso, './model/biome/rf_total_lasso.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "38a83c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_total_lasso_setup = PLSRegression(scale=True)\n",
    "param_grid = {'n_components': range(1,5)}\n",
    "gsearch = GridSearchCV(pls_total_lasso_setup, param_grid)\n",
    "pls_total_lasso = gsearch.fit(df_biome_data_total_lasso, df_biome_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "be043d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 6.397658320429045\n",
      "R2: 0.4143697711754174\n"
     ]
    }
   ],
   "source": [
    "Y_predict_pls_lasso = pls_total_lasso.predict(df_biome_test_data_tr_lasso)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_pls_lasso)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_pls_lasso)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5d9a2670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/biome/pls_total_lasso.pkl']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pls_total_lasso, './model/biome/pls_total_lasso.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0706d",
   "metadata": {},
   "source": [
    "#### 'pls_model_test.pkl' is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "611ee11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = joblib.load('./model/total/forest_total.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03dcef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: 3.769612731225027\n",
      "R2: 0.7966824475964466\n"
     ]
    }
   ],
   "source": [
    "Y_predict_forest = es.predict(df_biome_test_data_tr)\n",
    "m = mean_squared_error(df_biome_test_target, Y_predict_forest)\n",
    "print(\"root_mean_squared_error: \"+str(np.sqrt(m)))\n",
    "print(\"R2: \"+str(r2_score(df_biome_test_target, Y_predict_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4a9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
